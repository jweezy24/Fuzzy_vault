\section{Datasets}

\subsection{Voltkey Data}

One of the datasets we tested was a binary stream gathered from one Voltkey.
The data gathered from the Voltkey used the entropy correcting methodologies described in Voltkey's earlier work.
Voltkey's data passes a few of the NIST tests but not all.
The NIST tests where the data was fed into tests binary stream randomness.
The goal of these tests is to pass all of the tests to ensure that the randomness is secure enough to be used professionally.
The raw translation data does not reflect a confident source of randomness.
Although most would assume that isn't a good sign, the dataset actually is perfect for the Fuzzy Vault algorithm.
After implementing a simple algorithm that reads the stream and adds some simulated error to the stream, we saw the entire stream was able to be read correctly. %This is when the error was inputed at a high rate but wasnt going over the theoretical maximum.


\subsection{EJScreen Dataset}

The EJScreen dataset is environmental data gathered in a region.
The set is perfect because it doesn't store only one type of data, rather it stores several different environmental variables gathered from the node in question's surroundings.
Fuzzy vault is designed for sets like these.
Fuzzy vault scales with noise within the network.
Meaning, depending on the environment you can play into the noise to generate authentication keys.
